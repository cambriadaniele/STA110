\chapter{General notions in Probability}%
\label{cha:General notions in Probability}

\section{Probability spaces}%
\label{sec:Probability spaces}

\begin{definition}[]
    \label{def:10.1}
    Let $(\Omega, \mathcal{F})$ be a measurable space. A probability $\mathbb{P}$ on
    $\mathcal{F}$ is a measure on $\mathcal{F}$ s.t. $\mathbb{P}(\Omega) = 1$.
    The triple $(\Omega, \mathcal{F}, \mathbb{P})$ is referred to as a probability space.
\end{definition}

\begin{example}[]
    \label{ex:10.1}
    Let $\Omega$ be a finite and nonempety set. Define
    \[
    \mathbb{P}(A) = \frac{\#A}{\#\Omega}, \quad A \in \mathcal{P}(\Omega),
    .\] 
    Where $\mathcal{P}(\Omega)$ is the power set on $\Omega$. Then, $\mathbb{P}$ is a 
    probability on $\mathcal{P}(\Omega)$.
\end{example}

\begin{example}[]
    \label{ex:10.2}
    Let $C$ be a set s.t. $\#C = 52$. Suppose that
    \[
    C = S_1 \cup S_2 \cup  S_3 \cup S_4
    ,\] 
    with $\{S_1, S_2, S_3, S_4\} $ disjoint and s.t. $\#S_i = 13 \text{ for all } 
    i = 1,2,3,4$. We remain in the setting of the previous example with
    \[
    \Omega = \{A \subset C: \#A = 5\},
    \] 
    and $\mathbb{P}$ on $\mathcal{P}(\Omega)$ defined as in exercise ~\ref{ex:10.1}.
    Upon exercise ~\ref{ex:1.11}, we already know that $\#\Omega = \binom{52}{5}$.
    Let
    \[
    A_i = \{A \subset S_i: \#A = 5\}, \quad i=1,2,3,4, 
    \] 
    TODO
\end{example}

\section{Random variables and random vectors}%
\label{sec:Random variables and random vectors}

\begin{definition}[Random variable]
    \label{def:10.2}
    Let $(\Omega, \mathcal{F})$ be a measurable space. A map $X: \Omega \to \mathbb{R}$
    is referred to as a random variable on $(\Omega, \mathcal{F})$ if it if 
    $\mathcal{F}/ \mathfrak{B}(\mathbb{R})$ measurable.
\end{definition}

\begin{definition}[Random vector]
    \label{def:10.3}
    Let $(\Omega, \mathcal{F})$ be a measurable space. A map $X: \Omega \to \mathbb{R}^{k}$ 
    is referred to as a random vector on $(\Omega, \mathcal{F})$ if it is
    $\mathcal{F}/\mathfrak{B}(\mathbb{R}^{k})$ measurable.
\end{definition}

\begin{proposition}[]
    \label{prop:10.1}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X$ be a random
    vector on $(\Omega^{ }, \mathcal{F}^{})$. A random variable $Y$ on $(\Omega^{ }, \mathcal{F}^{ })$
    is $\sigma(X)$ measurable if and only if there exists a function
    $f: \mathbb{R}^{k} \to \mathbb{R}$ which is $\mathfrak{B}(\mathbb{R}^{k})$ measurable s.t.
    $Y = f(X)$.
\end{proposition}

\begin{definition}[]
    \label{def:10.4}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. The distribution or law of
    a random vector on $(\Omega^{ }, \mathcal{F}^{ })$ is the pushforward measure
    $P_X = \mathbb{P} X^{-1}$ on $\mathfrak{B}(\mathbb{R}^{k})$ (cf. Definition ~\ref{def:9.1}).
    In particular, for any $B \in \mathfrak{B}(\mathbb{R}^{k})$, we use the simplified notation
    \[
    \{\omega \in \Omega: X(\omega) \in B\} = \{X \in B\} 
    ,\] 
    and hence
    \[
    P_X(B) = \mathbb{P}(X^{-1}(B)) = \mathbb{P}(\{\omega \in \Omega: X(\omega) \in B\} ) =
    \mathbb{P}(X \in B)
    .\] 
    For now, unless mentioned otherwise, if $ (\Omega, \mathcal{F}, \mathbb{P})$ is a probability
    space, any random vector $X$ is a random vector on $(\Omega, \mathcal{F})$, i.e., a $\mathcal{F}$ 
    measurable function with values in $\mathbb{R}^{k}$.
\end{definition}

\section{Discrete laws}%
\label{sec:Discrete laws}
\begin{definition}[Discrete random vector]
    \label{def:10.5}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. A random vector is referred to as
    discrete if there exists a countable set $E = E_1 \times \ldots \times E_k \subset \mathbb{R}^{k}$ 
    s.t. $P_X(E)=1$. That is to say that the law of $X$ has a countable support.
\end{definition}

\begin{proposition}[Discrete random vector]
    \label{prop:10.2}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. A random vector $X$ is discrete if
    and only if
    \[
    P_X = \sum_{x \in E}^{} p_x {\delta}_x, \quad p_x = \mathbb{P}(X = x)
    ,\] 
    for some countable set $E = E_1 \times \ldots \times E_k \subset \mathbb{R}^{k}$. In particular, for
    any $B \in  \mathfrak{B}(\mathbb{R}^{k})$, $P_X(B) = \sum_{x \in B \cap E}^{} p_x$.
\end{proposition}

Proof of Proposition ~\ref{prop:10.2}. Suppose that $X$ is discrete. Let $B \in 
\mathfrak{B}(\mathbb{R}^{k})$. We have that
\[
P_X(B) = P_X(B \cap E) = \mathbb{P}(X \in B \cap E) 
= \mathbb{P}(\bigcup_{x \in B \cap E}\{X = x\} ) ) = \sum_{x \in B\cap E}^{ } p_x
= \sum_{x \in E}^{ } p_x {\delta}_x(B)
.\] 
with respect to the other direction, if $P_X$ is given as in Prop. ~\ref{prop:10.2}, then
\[
1 = P_X(\mathbb{R}^{k}) = \sum_{x \in E}^{ } p_x {\delta}_x(\mathbb{R}^{k})
= \sum_{x \in E}^{ } p_x = \mathbb{P}(X \in E) = P_x(E)
,\] 
i.e., $X$ is a discrete random vector according to Def. ~\ref{def:10.5}.

\begin{example}[Tail, head]
    \label{ex:Tail,_head}
    Let $\Omega = \{t, h\} $ and
    \[
    X(\omega) = 
    \begin{cases}
        0, & \text{if } w=t, \\
        1, & \text{if } w = h.
    \end{cases}
    \] 
    Then, $X$ is a random variable on $(\Omega, \mathcal{P}(\Omega))$.

    Explanation: for the cases $X^{-1}(0) = t$ and $X^{-1}(1) = h$ it is clear. Consider then 
    $X^{-1}(\omega) = \emptyset \in \mathcal{P}(\Omega) \text{ for any } \omega \not\in \{1, 2\} $.

    Suppose that $\mathbb{P}$ is a probability on $\mathcal{P}(\Omega)$ s.t. $\mathbb{P}(X^{-1}(0)) 
    = \mathbb{P}(X=0) = 1-p$ and $\mathbb{P}(X=1)=p$.     
    Clearly, $\mathbb{P}(X \in \{0,1\} ) = P_X(\{0,1\} ) = 1$. By Prop. ~\ref{prop:10.2}, we deduce
    that the law of $X$ is given by
    \[
    P_X = (1-p) \delta _0 + p\delta _1
    .\] 
    That is, for any $B \in \mathfrak{B}(\mathbb{R})$,
    \[
    P_X(B)= (1-p) \delta _0(B) + p\delta _1(B)=
    \begin{cases}
        0, & \text{if } 0 \not\in B \text{ and } 1 \not\in B \\
        1-p, & \text{if } 0 \in B \text{ and } 1 \not\in B \\
        p, & \text{if } 0 \not\in B \text{ and } 1 \in B \\
        1, & \text{if } 0 \in B \text{ and } 1 \in B \\
    \end{cases}
    .\] 
    For example, for $B = (2, 4]$, $X^{-1}(B) = \emptyset \in \mathcal{P}(\Omega)$, and
    $P_X(B) = P_X(\emptyset) = 0$. Also note that, for example, $\mathbb{P}(X=0) 
    = \mathbb{P}(X^{-1}(0)) = \mathbb{P}(t) = 1-p$.
\end{example}

\begin{myexample}[Examples of discrete probability distributions]
    \label{myex:Examples_of_discrete_probability_distributions} \hfill

\textbf{Discrete uniform:} $E \subset \mathbb{R}$ is a finite set s.t. $\#E=n$, and $p_x = \frac{1}{n}$ for any $x \in E$.

\textbf{Bernoulli:} $E = \{0,1\} $ and $p_0 = 1-p$ and $p_1 = p$, $p \in [0,1]$.

\textbf{Binomial:} $E=\{0,1, \ldots, n\} $, $n \in \mathbb{N}$ and $p_x=\binom{n}{x} p^{x}(1-p)^{n-x}$, $p \in [0,1]$.

\textbf{Geometric:} $E = \mathbb{N}$ and $p_x = (1-p)^{x-1}p$, $p \in (0,1)$.

\textbf{Poisson:} $E= \mathbb{N} \cup \{0\} $ and $p_x = (\frac{\lambda}{x!})e^{-\lambda}$, $\lambda>0$.

\textbf{Multinomial:} TODO: Write multinomial discrete probability distribution.
\end{myexample}

\begin{remark}[]
    \label{rem:10.3}
    If $X= (X_1, \ldots, X_k): \Omega \to \mathbb{R}^{k}$ is discrete with support $E = E_1, 
    \ldots, E_k$, we apply Prop. ~\ref{prop:10.2} and deduce that for any $i= 1, \ldots, k$,
    \begin{align*}
        \mathbb{P}(X_i = x) &= \mathbb{P}(X_1 \in \mathbb{R}, \ldots, X_{i-1}\in \mathbb{R},
        X_i = x, X_{i+1} \in \mathbb{R}, \ldots, X_k \in \mathbb{R}) \\
        &= P_X(\mathbb{R} \times \ldots\times \mathbb{R}\times  {x}\times\mathbb{R}\times 
        \ldots\times \mathbb{R}) \\
        &= \sum_{(x_1, \ldots, x_k)\in E, x_{i}=x}^{ } p_{x_1}, \ldots, x_k
    .\end{align*}
    Given $i=1,\ldots,k$, we apply the notation,
    \[
    x_{-i}=(x_1, \ldots, x_{i-1}, x_{i+1}, \ldots, x_k)
    ,\] 
    (Every $x$ apart from $x_{i}$). And,
    \[
    E_{-i} = E_1\times \ldots\times E_{i-1}\times E_{i+1}\times \ldots\times E_k
    .\] 
    Then, we obtain
    \[
    \mathbb{P}(X_i = x)= \sum_{x_{-i} \in E_{-i}}^{ } p_{x_1, \ldots, x_{i-1},x,x_{i+1}, \ldots, x_k}
    .\] 
    Notice that the sum is zero if $x \not\in E_i$ ($X_i $ has support $E_i$).
    For example, for $k=3$,
    \[
    \mathbb{P}(X_1 = x) = \sum_{(x_2, x_3)\in E_2\times E_3}^{} p_{x, x_2,x_3}
    ,\] 
    where
    \[
    p_{x, x_2,x_3} = \mathbb{P}(\{X_1=x\} \cap \{X_2 = x_2\} \cap \{X_3 = x_3\} )
    .\] 
\end{remark}

\section{Continuous laws}%
\label{sec:Continuous laws}
\begin{definition}[Continuous random vector]
    \label{def:10.6}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. A random vector is referred 
    to as continuous if the law of $X$ has density $\phi: \mathbb{R}^{k}\to [0, \infty)$ with 
    respect to the Lebesgue measure on $\mathfrak{B}(\mathbb{R}^{k})$,
    \[
    P_X(B)= \int_{B} \phi(x)dx
    .\] 
    The density $\phi$ of $P_X$ is referred to as a probability density function.
\end{definition}

\begin{myexample}[Classical examples of probability distributions with probability density function $\phi$]
    \label{myex:10.2}
    TODO: Write the probability distributions.

    \textbf{Continuous uniform:}

    \textbf{Exponential:}

    \textbf{Normal:}

    \textbf{Multivariate Normal:}
\end{myexample}

\begin{definition}[]
    \label{def:10.7}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. Suppose that fo any $\omega \in \Omega$,
    $S(\omega)$ is a statement on $\Omega$. We say $S$ is true $\mathbb{P}$ almost surely (a.s.) if 
    $\mathbb{P}(\{\omega: S(\omega) \text{ is true}\} )=1$. (Cf. Def. ~\ref{def:8.4}).
    
\end{definition}

\section{Expectation}%
\label{sec:Expectation}
\begin{definition}[Expectation of $X$]
    \label{def:10.9}
    TODO: Write definition
\end{definition}

\begin{proposition}[Expectation of $f(X)$]
    \label{prop:10.3}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X$ be a random vector.
    Then, for any nonnegative and $\mathfrak{B}(\mathbb{R}^{k})$ measurable map $f: \mathbb{R}^{k}\to 
    \overline{\mathbb{R}}$,
    \[
    \mathbb{E}[f(X)]= \int_{\mathbb{R}^{k}} f(x)P_X(dx)
    .\] 
    In addition, if $f$ is not necessarily nonnegative, this proposition holds if $\mathbb{E}[|f(X)|]<\infty$.
\end{proposition}

\section{Distribution function}%
\label{sec:Distribution function}

\begin{definition}[]
    \label{def:10.10}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X$ be a random variable. The distribution
    function $F$ of $X$ is defined by
    \[
        F_X(t) = \mathbb{P}(X \le t) = P_X((-\infty, t])
    .\] 
    
    \begin{remark}[]
        \label{rem:10.7}
        Using Prop. ~\ref{prop:10.2}, if $X$ is discrete , we have that for any $t \in \mathbb{R}$,
        \[
        F_X(t)=\sum_{x\in E, x\le t}^{ } p_x
        .\] 
        If $X$ is continuous with law that has probability density function $\phi$, we have upon Def.
        ~\ref{def:10.6} that for any $t \in \mathbb{R}$,
        \[
            F_X(t) \int_{(-\infty, t]} \phi(x)dx
        .\] 
    \end{remark}
\end{definition}




