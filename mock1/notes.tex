\chapter{Mock exam 1}%
\label{cha:Mock exam 1}
Solve with the pdf of the mock exam on the side.

\textbf{Notation:} We recall some of the terminology:
\begin{itemize}
    \item Given a nonempty set $\Omega$, $\mathcal{P}(\Omega)$ is the power set on $\Omega$;
    \item $\mathfrak{B}(\mathbb{R}^k)$ denotes the Borel $\sigma$-field on $\mathbb{R}^k$, $k \geq 1$;
    \item The measure
    \[
    \mu(A) = 
    \begin{cases} 
    \#A, & \text{if } A \text{ is finite} \\
    \infty, & \text{otherwise},
    \end{cases}
    \quad A \in \mathcal{P}(\Omega),
    \]
    is referred to as the counting measure on $\mathcal{P}(\Omega)$;
    \item Given a measurable space $(\Omega, \mathcal{F})$ and $x \in \Omega$, we write $\delta_x$ for the measure
    \[
    \mathcal{F} \ni A \mapsto \delta_x(A) = 
    \begin{cases} 
    1, & \text{if } x \in A \\
    0, & \text{otherwise}.
    \end{cases}
    \]
\end{itemize}

\begin{exercise}[]
    \label{ex:mock1}
    \begin{enumerate}[label=(\alph*)] \hfill
        \item Refer to Def. ~\ref{def:4.1}.

        \item Measure on $\mathcal{F}$ (cf. Def ~\ref{def:5.1}).
            \begin{itemize}
                \item 
                    \begin{enumerate}[label=(\roman*)]
                        \item $\mu_1(\emptyset) = C\mu(\emptyset)= 0$;
                        \item We know that item ii holds for the counting measure by definition. For our redefined
                            counting measure,
                            \[
                            \mu_1(\bigcup_{i \in \mathbb{N}} A_i) = C\mu(\bigcup_{i \in \mathbb{N}} A_i)
                            = C \sum_{i \in \mathbb{N}}^{ } \mu(A_i) = \sum_{i \in \mathbb{N}}^{ } C\mu(A_i)
                            = \sum_{i \in \mathbb{N}}^{ } \mu_1(A_i)
                            .\] 
                    \end{enumerate}

                \item
                    \begin{enumerate}[label=(\roman*)]
                        \item $\mu_2(\emptyset) = \int_{\emptyset} f(\omega)\mu(d\omega) = 0$;
                        \item 
                            \[
                            \mu_2(\bigcup_{i \in \mathbb{N}} A_i) = \int_{\bigcup_{i \in \mathbb{N}} A_i} f(\omega)\mu(d\omega)
                            \stackrel{\text{Tool ~\ref{tool:8.9}}}
                            {=} \sum_{i \in \mathbb{N}}^{ }\int_{A_i}  f(\omega)\mu(d\omega) 
                            = \sum_{i \in N}^{ } \mu_2(A_i)
                            .\] 
                    \end{enumerate}

                \item
                    \begin{enumerate}[label=(\roman*)]
                        \item $\mu_3(\emptyset) = \frac{1}{2} + \lambda(\emptyset) = \frac{1}{2}$. 
                    \end{enumerate}
            \end{itemize}
            We see that  $\mu_3$ is clearly not a measure on $\mathcal{F}$.

        \item Probability measure cf. Def. ~\ref{def:10.1}.
            \begin{itemize}
                \item 
                    \[
                    P_1(\mathbb{R}) = \int_{\mathbb{R}} \mathbbm{1}_{[0, \infty)}(x) e^{-x}dx
                    = \int_{[0, \infty)} e^{-x}dx 
                    = (-e^{-x})|_0^{\infty} = (0 - (-1)) = 1
                    .\] 
                \item
                    \[
                    P_2(\mathbb{N}) = \int_{\mathbb{N}} \mathbbm{1}_{\{0,1\} }(x) x^{2}\mu(dx) 
                    = \int_{\{0,1\} } x^{2}\mu(dx) = 0^{2}\cdot \mu(\{0\} ) + 1^{2}\cdot \mu(\{1\} ) 
                    = 0\cdot 1 + 1 \cdot 1 = 1
                    .\] 
                \item
                    \begin{tool}[Integral with respect to a dirac measure]
                        \label{tool:iwrtadm} 
                        \[
                        \int_{\Omega} f(x) \delta_\omega(dx) = f(\omega)
                        .\] 
                    \end{tool}
                    \[
                    P_3(\mathbb{R}) = \int_{\mathbb{R}} x^{2}\mu(dx) 
                    = \int_{\mathbb{R}} x^{2} (\delta_{-1}(dx)+ \delta_1(dx))
                    = \int_{\mathbb{R}} x^{2} \delta_{-1}(dx) + \int_{\mathbb{R}}x^{2} \delta_1(dx)
                    \] 
                    \[
                    = (-1)^{2} + 1^{2} = 2
                    .\] 
            \end{itemize}
            We see that $P_3$ is not a probability measure on $\mathcal{B}$.

        \item Calculate:
            \begin{enumerate}[label=\arabic*.]
                \item $\lambda$ Lebesgue measure on $\mathfrak{B}(\mathbb{R})$.
                    \[
                    \int_{\mathbb{R}} \mathbbm{1}_{[-1,1]}(x) \lambda(dx)
                    = \int_{[-1,1]} 1 \lambda(dx) = 1 \cdot \lambda([-1,1]) = 1 \cdot 2 = 2
                    .\] 
                \item $P(A) = (1-p)\delta_0(A) + p \delta_1(A)$, $A \in \mathfrak{B}(\mathbb{R})$, $p \in (0,1)$.
                    \[
                    \int_{\mathbb{R}} (x-p)^{2}P(dx)
                    = \int_{\mathbb{R}} (x-p)^{2} ((1-p)\delta_0(dx)) + \int_{\mathbb{R}} (x-p)^{2}(p\delta_1(dx))
                    = (0-p)^{2}(1-p) + (1-p)^{2}p
                    \] 
                    \[
                    = p^{2} -p^{3} + p + p^{3} -2p^{2} = p-p^{2}
                    .\] 
                \item $\lambda$ Lebesgue measure on $\mathfrak{B}(\mathbb{R})$. As the Lebesgue measure of a singleton 
                    is equal to $0$
                    \[
                    \int_{\mathbb{N}} \log(x)\lambda(dx) = 0
                    .\] 
            \end{enumerate}
        \item
            Refer to Def. ~\ref{def:10.5}, Prop. ~\ref{prop:10.2}.
            \begin{enumerate}[label=\arabic*.]
                \item The support is $E=\{0,1\} $, countable.
                    \[
                    P_1(E) = \frac{1}{2} \cdot 1 + \frac{1}{2} \cdot 1 = 1
                    .\] 
                \item As $F_X$ is continuous, $\mathbb{P}(X=x)=0$, $\forall x \in \mathbb{R}$. This means that there exists
                    no countable set $E$ s.t. $P_X(E)=1$.
                \item The support is $E=\{0,1\} $, countable.
                    \[
                    P_3(A) = \mathbb{P}(X=1)\cdot \delta_1(A) + \mathbb{P}(X=0)\cdot \delta_0(A)
                    .\] 
                    Where $\mathbb{P}(X=1) = \mathbb{P}(X^{-1}(1)) = \mathbb{P}(h)$.
            \end{enumerate}
            $P_2$ is not a discrete law.
        \item  TODO: Understand and complete. Cf. Sec. ~\ref{sec:Gauss vectors}.

    \end{enumerate}
\end{exercise}

\begin{exercise}[]
    \label{ex:12.2}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X$ be a discrete random variable on $\Omega$ with 
    support $\{-1,1\} $ and law
    \[
    P_X(A)= \frac{1}{2} \delta_{-1}(A)+\frac{1}{2}\delta_1(A)
    .\] 
    \begin{enumerate}[label=(\alph*)]
        \item
            $\mathbb{P}(X=-1)= P_X(\{-1\} ) = \frac{1}{2}$,
            $\mathbb{P}(X=1) = \frac{1}{2}$
        \item We have that $f(X)=|X|^{2}$, cf. Prop. ~\ref{prop:10.3}
            \[
            \mathbb{E}(|X|^{2}) = \int_{\mathbb{R}}|x|^{2}P_X(dx) 
            = \frac{1}{2} \int_{\mathbb{R}}  \left|x \right|^2 \delta_{-1}(dx) 
            + \frac{1}{2} \int_{\mathbb{R}}  \left|x \right|^2 \delta_{1}(dx)
            = \frac{1}{2}( \left|-1 \right| ^2) + \frac{1}{2}( \left|1 \right| ^2) = 1
            .\] 
        \item $\mathbb{E}[X] = -\frac{1}{2} + \frac{1}{2}= 0$. We than know that
            \[
            Var(X) =\mathbb{E}[X^{2}] - \mathbb{E}[X]^{2} = 1-0=1
            .\] 
        \item
            We can find the support of $\frac{X+1}{2}$.
            \[
                \mathbb{P}\left( \frac{X+1}{2}=\omega \right) \neq 0 \Rightarrow X = 2\omega - 1 = \{-1,1\} 
            .\] 
            For $2\omega-1 = -1$, $\omega=0$, and for  $2\omega-1 = 1$,  $\omega=1$. 
            The support of  $\frac{X+1}{2}$ is $\{0,1\} $.
            In particular
            \[
            \mathbb{P}\left( \frac{X+1}{2} = 0 \right) = \mathbb{P}\left( X=-1 \right) = \frac{1}{2}
            .\] 
            and
            \[
            \mathbb{P}\left( \frac{X+1}{2} = 1 \right) = \mathbb{P}\left( X=1 \right) = \frac{1}{2}
            .\] 
        \item
          The law of $Y $ is given by the product measure of the individual laws of the random vectors
          on $\mathfrak{B}(\mathbb{R}) \otimes \ldots \otimes \mathfrak{B}(\mathbb{R}) $, cf.
          Prop. ~\ref{prop:11.1}
          \[
          P_Y(A) = P_{Y_1}\otimes\ldots\otimesP_{Y_n}(A), \quad A \in 
          \mathfrak{B}(\mathbb{R}) \otimes \ldots \otimes \mathfrak{B}(\mathbb{R}) 
          .\] 
        \item
          TODO: Do exercise
        \item
          TODO: Do exercise
    \end{enumerate}
\end{exercise}

\begin{exercise}[]
    \label{ex:12.3}
    Let
    \[
    \phi(x) = \begin{cases}
        0 & x<-3, \\
        \frac{1}{3} + \frac{1}{9}x & -3 \le x < 0 \\
        \frac{1}{3} - \frac{1}{9}x & 0 \le x < 3 \\
        0 & x\ge 3.
    \end{cases}
    \] 
    \begin{enumerate}[label=(\alph*)]
        \item Verify that $\int_{\mathbb{R}} \phi(x)dx = 1$
            \begin{align*}
                \int_{\mathbb{R}} \phi(x)dx 
                &=\int_{[-3,0)} \left( \frac{1}{3}+\frac{1}{9}x\right)dx +\int_{[0,3)} \left( \frac{1}{3} - \frac{1}{9}x \right)dx \\ 
                &= \left[\frac{x}{3} + \frac{x^{2}}{18}\right]_{-3}^{0} + \left[\frac{x}{3} - \frac{x^{2}}{18}\right]_{0}^{3} \\
                &= 0 - \left( -1 + \frac{1}{2} \right) + \left( 1-\frac{1}{2} \right)  - 0 = 1\\            
            \end{align*}
    \end{enumerate}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X$ be a random variable on $\Omega$ with law 
    $P_X(dx) = \phi(x)dx$.
    \begin{enumerate}[label=(\alph*), start=2]
        \item Find the distribution function $F_X$ of $X$.
            \[
            F_X(t) = \int_{[-3, t]} \phi(x) 
            .\] 
            For $t \in [-3, 0)$ 
            \[
            F_X(t)= \int_{[-3, t]} \left( \frac{1}{3} + \frac{1}{9}x \right)dx 
            = \left[ \frac{x}{3} + \frac{x^{2}}{18} \right]_{-3}^{t} 
            = \frac{t}{3} + \frac{t^2}{18} +\frac{1}{2} 
            .\] 
            For $t \in [0, 3) $ 
            \begin{align*}
                F_X(t) &= \int_{[-3, 0)}\left( \frac{1}{3} + \frac{x}{9} \right) dx 
                + \int_{[0, t)} \left( \frac{1}{3} - \frac{x}{9} \right) dx\\
                &= \left[ \frac{x}{3} + \frac{x^2}{18} \right]_{-3}^{0} 
                + \left[ \frac{x}{3} - \frac{x^2}{18} \right]_{0}^{t}\\
                &= \frac{1}{2} + \frac{t}{3} - \frac{t^2}{18} \\
            .\end{align*}
            We obtain
            \[
            F_X(t) = 
            \begin{cases}
                0, & t < -3 \\
                \frac{t}{3} + \frac{t^2}{18} + \frac{1}{2}, & -3 \le t <0 \\
                \frac{t}{3} - \frac{t^2}{18} +\frac{1}{2}, & 0 \le t<3 \\
                1, & t \ge 3
            \end{cases}
            .\] 
        \item Calculate the expected value and the variance of $X$.
             \begin{itemize}
                \item Expected value
                    \begin{align*}
                        \mathbb{E}(X) &= \int_{\mathbb{R}} x\phi(x) dx
                        = \int_{[-3,0)}\left( \frac{x}{3} + \frac{x^2}{9} \right) dx
                        + \int_{[0,3)}\left( \frac{x}{3} - \frac{x^2}{9} \right) dx\\
                        &= \left[ \frac{x^2}{6} + \frac{x^{3}}{27} \right]_{-3}^{0}  
                        +\left[ \frac{x^2}{6} - \frac{x^{3}}{27} \right]_{0}^{3}
                        = 0 - (\frac{3}{2} - 1) + \frac{3}{2} - 1 -0 =0\\
                    .\end{align*}
                \item Variance
                    \begin{align*}
                        Var(X) &= \mathbb{E}(X^{2})
                        = \int_{[-3,0)}\left( \frac{x^2}{3} + \frac{x^3}{9} \right) dx
                        + \int_{[0,3)}\left( \frac{x^2}{3} - \frac{x^3}{9} \right) dx\\
                        &= \left[ \frac{x^3}{9} + \frac{x^{4}}{36} \right]_{-3}^{0}  
                        +\left[ \frac{x^3}{9} - \frac{x^{4}}{36} \right]_{0}^{3}
                        = 0 - (-3 + \frac{9}{4}) + 3 - \frac{9}{4} -0 = \frac{3}{2}\\
                    .\end{align*}
            \end{itemize}
        \item Show that $F_X|_{(-3,3)}: (-3, 3) \to (0,1) $ is a bijection. We know that 
            $F_X $ is continuous on $\mathbb{R} $. 

            For $t \in (-3, 0) $
            \begin{align*}
                F'_X(t) = \frac{1}{3} + \frac{t}{9} > \frac{1}{3} + -\frac{3}{9} = 0
            .\end{align*}

            For $t \in [0, 3) $
            \begin{align*}
                F'_X(t) = \frac{1}{3} - \frac{t}{9} > \frac{1}{3} - \frac{3}{9} = 0
            .\end{align*}

            $F'_X(t)|_{(-3,3)} > 0 $ for every
            $ t \in (-3, 3) \Rightarrow F_X(t)|_{(-3,3)}$
            is monotonically increasing for every $t \in (-3, 3) \Rightarrow F_X(t)|_{(-3,3)}$
            is bijective.
        \item
          TODO: Do exercise
        \item
          TODO: Do exercise
    \end{enumerate}
\end{exercise}

\begin{exercise}[]
    \label{ex:12.4}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X_1 $ and $X_2 $ be two
    random variables on $\Omega$ that are independent with common law that is continuous uniform
    on the interval $\left[ 0,1 \right]  $. what is the probability density function of the
    random vector $Y=(X_1, 2\sqrt{X_2} ) $.

    Refer to Prop. ~\ref{prop:11.4}
    \begin{align*}
      \phi(y) = \phi_1(y_1)\phi_2(y_2), \quad y = (y_1, y_2) \in \mathbb{R}^{2}
    .\end{align*}
    We know that 
    \begin{align*}
      \phi_1(y_1)= \mathbbm{1}_{[0,1]}(y_1), \quad y_1 \in \mathbb{R} 
    .\end{align*}
    For the probability density function of $2\sqrt{X_2}  $, refer to Example ~\ref{ex:10.20}.
    
    By Prop. ~\ref{prop:10.3}, we know that 
    \[
      \mathbb{E}(f(Y_2)) = \mathbb{E}(f(2\sqrt{X_2} )) 
      = \int_{0}^{1} f(2\sqrt{x_2})dx_2.
    \] 
    We then substitute $y_2 = 2\sqrt{x_2} $,  $\left( x_2 = \left( \frac{y_2}{2} \right)^2  \right)$,
    $\left( dy_2 = x_2^{-\frac{1}{2}} dx_2 
    \Rightarrow dy_2 = \frac{2}{y_2}dx_2 \Rightarrow dx_2 = 2^{-1}y_2\right)  $,
    $\left( x_2 \in \left[ 0,1 \right]
    \Rightarrow y_2 \in \left[ 0,2 \right]  \right)  $.
    \[
    \mathbb{E}(f(Y_2)) = \int_{0}^{2} f(y_2)2^{-1}y_2dy_2 = \int_{\mathbb{R}} f(y_2)\mathbbm{1}_{[0,2]}(y_2)2^{-1}y_2dy_2
    .\] 
    Hence, the law of $Y_2 $ is given by
    \[
    \phi(y_2) = \mathbbm{1}_{[0,2]}(y_2)2^{-1}y_2, \quad y_2 \in \mathbb{R}
    .\] 

    In conclusion
    \[
      \phi(y_1, y_2) = \mathbbm{1}_{\left[ 0,1 \right] }(y_1) \mathbbm{1}_{\left[ 0,2 \right] }(y_2) 2^{-1}y_2 
    .\] 
\end{exercise}

\begin{exercise}[]
    \label{ex:12.5}
    Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $X$ be a discrete random variable on $\Omega$ with 
    support $\{1,\ldots, N\} $, where $N\ge 2$ and $N$ is even. Suppose that $X$ has law defined upon:
    \[
    \mathbb{P}(X=k) = C_N max \{k, N-k\}, \quad k=1,\ldots,N
    ,\] 
    Where $C_N \in \mathbb{R}$. Find $C_N$.

    As $N$ is even, we can find a middle point $m = \frac{N}{2}$. I will use $N=2m$.
    \begin{align*}
    \sum_{k=1}^{N} \mathbb{P}(X = k) &= C_N(\sum_{k=1}^{m} (2m - k) + \sum_{k=m+1}^{2m} k )\\
    &= C_N(\sum_{k=1}^{m} (2m - k) + \sum_{j=1}^{m} (m + j)) \\
    &= C_N(2m\cdot m - \sum_{k=1}^{m} k + m\cdot m  + \sum_{j=1}^{m} j) \\
    &= C_N(3m^{2}) \\
    &= C_N(3(\frac{N}{2})^{2})
    \end{align*}
    By definition
    \[
    C_N(\frac{3N^{2}}{4}) = 1 \Rightarrow C_N = \frac{4}{3N^{2}}
    .\] 
\end{exercise}
